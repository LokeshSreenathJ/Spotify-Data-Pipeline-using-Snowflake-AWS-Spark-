# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BIDIz7IyOTkV_8pbxip3YcjeoT9Hhg78
"""

import sys


from pyspark.sql import SparkSession
from pyspark import SparkContext
from pyspark.sql.types import *


spark = SparkSession \
        .builder \
        .appName("Oracle_to_snowflake_via_S3") \
        .getOrCreate()



def main():
    s3_bucket=sys.argv[1];
    s3_file=sys.argv[2];
    s3_location="s3a://{}/{}".format(s3_bucket,s3_file);
    def convert_nested_json_csv(df):
  #Let's first focus on complex datatypes like arrays and Structure Types
      complex_fields = dict([(field.name, field.dataType)
                                for field in df.schema.fields
                                if type(field.dataType) == ArrayType or  type(field.dataType) == StructType])
      while len(complex_fields)!=0:
          #iterate over every complex Structure type
          col_name=list(complex_fields.keys())[0]

          #flatten structs
          if (type(complex_fields[col_name]) == StructType):
            expanded = [col(col_name+'.'+k).alias(col_name+'_'+k) for k in [ n.name for n in  complex_fields[col_name]]]
            df=df.select("*", *expanded).drop(col_name)

          # if ArrayType then add the Array Elements as Rows using the explode function
          # i.e. explode Arrays
          elif (type(complex_fields[col_name]) == ArrayType):
            df=df.withColumn(col_name,explode_outer(col_name))

          # recompute remaining Complex Fields in Schema
          complex_fields = dict([(field.name, field.dataType)
                                for field in df.schema.fields
                                if type(field.dataType) == ArrayType or  type(field.dataType) == StructType])
      return df
    df_flatted = convert_nested_json_csv(df)

    #Creating the tables
    album_df = df_flatted.select("track_album_id","track_album_name","track_album_release_date","track_album_total_tracks","track_album_uri","track_album_available_markets").dropDuplicates()
    album_df = album_df.withColumnRenamed("track_album_id","album_id").withColumnRenamed("track_album_name","album_name").withColumnRenamed("track_album_uri","album_uri").\
    withColumnRenamed("track_album_available_markets","available_markets")
    album_df = album_df.withColumn("release_date",to_date("track_album_release_date","yyyy-MM-dd")).withColumn("total_tracks",col("track_album_total_tracks").cast(IntegerType())).\
    drop("track_album_release_date","track_album_total_tracks")
    #Since we are restricted within USA, India and Canada, let's filter further down
    interested_countries =["IN","US","CA"]
    album_df = album_df.filter(album_df.available_markets.isin(interested_countries))

    #table song_list
    track_df = df_flatted.select("track_id","track_name","track_duration_ms","track_uri","track_popularity","track_album_id","track_artists_id","added_at").dropDuplicates()
    track_df = track_df.withColumnRenamed("track_album_id","album_id").withColumnRenamed("track_artists_id","artist_id")
    track_df = track_df.withColumn("track_duration",(round(col("track_duration_ms")/60000,2)).cast(DoubleType())).withColumn("track_popularity",col("track_popularity").cast(IntegerType())).\
    drop("track_duration_ms")
    track_df = track_df.withColumn("track_added",substring(track_df.added_at,1,10).cast(DateType())).drop("added_at")

    #Artist Table
    artist_df = df_flatted.select("track_artists_id","track_artists_name","track_artists_uri").dropDuplicates()
    artist_df = artist_df.withColumnRenamed("track_artists_id","artist_id").withColumnRenamed("track_artists_name","artist_name").withColumnRenamed("track_artists_uri","artist_uri")

    album_df.coalesce(1).write.format("csv").option("header", "true").save("s3://spotify-project-ljakka2/raw_data/processed/album/")
    track_df.coalesce(1).write.format("csv").option("header", "true").save("s3://spotify-project-ljakka2/raw_data/processed/track/")
    artist_df.coalesce(1).write.format("csv").option("header", "true").save("s3://spotify-project-ljakka2/raw_data/processed/artist/")

main()